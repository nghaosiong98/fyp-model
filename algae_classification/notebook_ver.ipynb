{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of algae_classification_final",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZomKjtEqNPc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOE5o-iPp2fr"
      },
      "source": [
        "import random\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight, shuffle\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, classification_report\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import regularizers, optimizers\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "\n",
        "from tqdm import tqdm\n",
        "from google.colab.patches import cv2_imshow\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vch9njzMukGR"
      },
      "source": [
        "# Path\r\n",
        "data_path = '/content/drive/My Drive/fyp/data'\r\n",
        "input_csv = os.path.join(data_path, 'classification_data/algae_classification.csv')\r\n",
        "image_path = os.path.join(data_path, 'images')\r\n",
        "test_data = os.path.join(data_path, 'test_data')\r\n",
        "output_path = \"/content/drive/MyDrive/fyp/model/\"\r\n",
        "model_path = os.path.join(output_path, 'algae_classification_mobilenetv2_fine_tuned_output')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zld3OSDk1tJ3"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdixsZNaS8BJ"
      },
      "source": [
        "all_data = pd.read_csv(input_csv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beYTOjmMTLv5"
      },
      "source": [
        "train, testval = train_test_split(all_data, test_size=0.3, random_state=22)\n",
        "val, test = train_test_split(testval, test_size=0.5, random_state=23)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05ntUzbaav5z"
      },
      "source": [
        "train = train.reset_index(drop=True)\n",
        "val = val.reset_index(drop=True)\n",
        "test = test.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvVbAI0ew5Vf"
      },
      "source": [
        "onehotencoder = OneHotEncoder()\n",
        "trainY = np.array(train.status.tolist())\n",
        "trainY = onehotencoder.fit_transform(trainY.reshape(-1, 1)).toarray()\n",
        "valY = np.array(val.status.tolist())\n",
        "valY = onehotencoder.fit_transform(valY.reshape(-1, 1)).toarray()\n",
        "testY = np.array(test.status.tolist())\n",
        "testY = onehotencoder.fit_transform(testY.reshape(-1, 1)).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mrbvNSoyoIA"
      },
      "source": [
        "# Data augmentation functions\n",
        "\n",
        "def fill(img, h, w):\n",
        "    img = cv2.resize(img, (h, w), cv2.INTER_CUBIC)\n",
        "    return img\n",
        "\n",
        "def horizontal_flip(img, flag):\n",
        "    if flag:\n",
        "        return cv2.flip(img, 1)\n",
        "    else:\n",
        "        return img\n",
        "\n",
        "def random_rotate(img, min_angle, max_angle):\n",
        "    rotation_angle = random.uniform(min_angle, max_angle)\n",
        "    rotated_img = ImageDataGenerator().apply_transform(x=img, transform_parameters={'theta': rotation_angle}) \n",
        "    return rotated_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyDfztIeyvZe"
      },
      "source": [
        "def generator(data, Y, batch_size = 32, flip = False, rotation = False):\n",
        "    while True:\n",
        "        for start in range(0, len(data), batch_size):\n",
        "            x_batch = []\n",
        "            y_batch = []\n",
        "            end = min(start + batch_size, len(data))\n",
        "            for i in range(start, end):\n",
        "                img = cv2.imread(os.path.join(image_path,data['filename'][i]))\n",
        "                img = cv2.resize(img, (224, 224))\n",
        "                x_batch.append(img)\n",
        "                y_batch.append(Y[i])\n",
        "                if flip:\n",
        "                    flip_img = horizontal_flip(img, True)\n",
        "                    x_batch.append(flip_img)\n",
        "                    y_batch.append(Y[i])\n",
        "                if rotation:\n",
        "                    rotated_img = random_rotate(img, -90.0, 90.0)\n",
        "                    x_batch.append(rotated_img)\n",
        "                    y_batch.append(Y[i])\n",
        "            x_batch, y_batch = shuffle(x_batch, y_batch)\n",
        "            yield np.array(x_batch),np.array(y_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8mhtCQpy-hl"
      },
      "source": [
        "train_label_list = train[\"status\"].tolist()\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(train_label_list),\n",
        "                                                 train_label_list)\n",
        "calculated_weights = {\n",
        "    0: class_weights[0],\n",
        "    1: class_weights[1],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3ulrKA8y4MQ"
      },
      "source": [
        "base_model = MobileNetV2(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(224,224,3)\n",
        "    )\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = keras.Input(shape=(224,224,3))\n",
        "\n",
        "x = base_model(inputs, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "outputs = Dense(2, activation='softmax')(x)\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer = keras.optimizers.Adam(),\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.CategoricalAccuracy()]\n",
        "    )\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-glea62PScQ"
      },
      "source": [
        "hist = model.fit(\n",
        "    x=generator(train, trainY, 16, flip=True, rotation=True),\n",
        "    epochs=20,\n",
        "    steps_per_epoch=10,\n",
        "    class_weight= calculated_weights,\n",
        "    validation_data=generator(val, valY, 16, rotation=True),\n",
        "    validation_steps=3\n",
        "    ).history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IPU_Sg8zQII"
      },
      "source": [
        "plt.figure()\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(hist[\"loss\"] ,label='train')\n",
        "plt.plot(hist[\"val_loss\"], label='val')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(hist[\"categorical_accuracy\"],label='train')\n",
        "plt.plot(hist[\"val_categorical_accuracy\"],label='val')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PZoMkw2_zNc"
      },
      "source": [
        "pred = model.predict(\n",
        "    x = generator(test, testY, 1),\n",
        "    steps = len(test),\n",
        "    verbose = 1\n",
        ")\n",
        "test_preds = np.argmax(pred, axis=1)\n",
        "test_trues = np.argmax(testY, axis=-1)\n",
        "print('Confusion matrix:\\n', confusion_matrix(test_trues, test_preds))\n",
        "print('F1 score:\\n', classification_report(test_trues, test_preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y90haMeWnXw"
      },
      "source": [
        "base_model.trainable = True\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-5),  # Very low learning rate\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcFv8MqUZP7R"
      },
      "source": [
        "hist = model.fit(\n",
        "    x=generator(train, trainY, 16, shift=False, flip=True, channel=False, zoom=False, brightness=False, rotation=True),\n",
        "    epochs=10,\n",
        "    steps_per_epoch=10,\n",
        "    class_weight= calculated_weights,\n",
        "    validation_data=generator(val, valY, 16, rotation=True),\n",
        "    validation_steps=3\n",
        "    ).history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmwQrHxGuSU_"
      },
      "source": [
        "plt.figure()\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(hist[\"loss\"] ,label='train')\n",
        "plt.plot(hist[\"val_loss\"], label='val')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(hist[\"categorical_accuracy\"],label='train')\n",
        "plt.plot(hist[\"val_categorical_accuracy\"],label='val')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CYkXa3NzRcf"
      },
      "source": [
        "pred = model.predict(\n",
        "    x = generator(test, testY, 1),\n",
        "    steps = len(test),\n",
        "    verbose = 1\n",
        ")\n",
        "test_preds = np.argmax(pred, axis=1)\n",
        "test_trues = np.argmax(testY, axis=-1)\n",
        "print('Confusion matrix:\\n', confusion_matrix(test_trues, test_preds))\n",
        "print('F1 score:\\n', classification_report(test_trues, test_preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMZlm6U40w2a"
      },
      "source": [
        "# Save model checkpoint\r\n",
        "model.save(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poRDlH4k1wAT"
      },
      "source": [
        "# Load saved model and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWU9pDIzfbQU"
      },
      "source": [
        "model = tf.keras.models.load_model(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5uoTyZK3zzh"
      },
      "source": [
        "test_data = []\n",
        "for image in glob.glob(os.path.join(test_data, \"*\")): \n",
        "    img = cv2.imread(image)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    test_data.append(img)\n",
        "test_preds = model.predict(\n",
        "    np.array(test_data),\n",
        "    steps=len(test_data)\n",
        ")\n",
        "test_preds = np.argmax(test_preds, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}